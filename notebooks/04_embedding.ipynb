{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f47e0c4",
   "metadata": {},
   "source": [
    "## <center style=\"color:red\">**News Classifier**</center>\n",
    "\n",
    "### <center>**ML Pipeline with Sentence Transformers, ChromaDB & Airflow**</center>\n",
    "\n",
    "Ce projet vise à construire un pipeline complet de classification de textes permettant de catégoriser automatiquement des articles d’actualité dans 4 classes :\n",
    "\n",
    "- World\n",
    "- Sports\n",
    "- Business\n",
    "- Sci/Tech\n",
    "\n",
    "Le pipeline utilise des techniques NLP avancées, des embeddings vectoriels, une base de données vectorielle et une orchestration via Apache Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e3b80",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <span style=\"color:green\">**Embeddings & Vectorisation :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37203a34",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">**1. Charger les Données :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2f5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données Chargées avec Succès !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wall st. bears claw back into the black (reute...</td>\n",
       "      <td>wall bears claw back black reuters reuters wal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carlyle looks toward commercial aerospace (reu...</td>\n",
       "      <td>carlyle looks toward commercial aerospace reut...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil and economy cloud stocks' outlook (reuters...</td>\n",
       "      <td>oil economy cloud stocks outlook reuters reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iraq halts oil exports from main southern pipe...</td>\n",
       "      <td>iraq halts oil exports main southern pipeline ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil prices soar to all-time record, posing new...</td>\n",
       "      <td>oil prices soar record posing new menace us ec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  wall st. bears claw back into the black (reute...   \n",
       "1  carlyle looks toward commercial aerospace (reu...   \n",
       "2  oil and economy cloud stocks' outlook (reuters...   \n",
       "3  iraq halts oil exports from main southern pipe...   \n",
       "4  oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                          clean_text  label  \n",
       "0  wall bears claw back black reuters reuters wal...      2  \n",
       "1  carlyle looks toward commercial aerospace reut...      2  \n",
       "2  oil economy cloud stocks outlook reuters reute...      2  \n",
       "3  iraq halts oil exports main southern pipeline ...      2  \n",
       "4  oil prices soar record posing new menace us ec...      2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "\n",
    "print(\"Données Chargées avec Succès !\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8ed7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données Chargées avec Succès !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fears for t n pension after talks unions repre...</td>\n",
       "      <td>fears n pension talks unions representing work...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the race is on: second private team sets launc...</td>\n",
       "      <td>race second private team sets launch date huma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ky. company wins grant to study peptides (ap) ...</td>\n",
       "      <td>company wins grant study peptides ap ap compan...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prediction unit helps forecast wildfires (ap) ...</td>\n",
       "      <td>prediction unit helps forecast wildfires ap ap...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calif. aims to limit farm-related smog (ap) ap...</td>\n",
       "      <td>aims limit smog ap ap southern california agen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  fears for t n pension after talks unions repre...   \n",
       "1  the race is on: second private team sets launc...   \n",
       "2  ky. company wins grant to study peptides (ap) ...   \n",
       "3  prediction unit helps forecast wildfires (ap) ...   \n",
       "4  calif. aims to limit farm-related smog (ap) ap...   \n",
       "\n",
       "                                          clean_text  label  \n",
       "0  fears n pension talks unions representing work...      2  \n",
       "1  race second private team sets launch date huma...      3  \n",
       "2  company wins grant study peptides ap ap compan...      3  \n",
       "3  prediction unit helps forecast wildfires ap ap...      3  \n",
       "4  aims limit smog ap ap southern california agen...      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "print(\"Données Chargées avec Succès !\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9de5b1",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">**2. Encoder les Textes d’Entraînement et Test :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1127486",
   "metadata": {},
   "source": [
    "##### **2.1. Sentence Transformer :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993617d8",
   "metadata": {},
   "source": [
    "Un `Sentence Transformer` est un modèle de langage basé sur l’architecture **Transformer**, spécialement conçu pour produire des représentations vectorielles (**embeddings**) de phrases plutôt que de simples mots. \n",
    "\n",
    "Contrairement aux modèles classiques qui analysent chaque mot séparément, un `Sentence Transformer` capture le sens global d’une phrase, sa structure et ses relations sémantiques. Cela permet de :\n",
    "\n",
    "- Comparer facilement deux phrases (similarité).\n",
    "\n",
    "- Regrouper des textes proches.\n",
    "\n",
    "- Faire de la recherche intelligente, du clustering, ou encore d’alimenter des modèles de classification avec des représentations beaucoup plus riches et précises. \n",
    "\n",
    "En pratique, il est largement utilisé dans des tâches de NLP comme la détection de doublons, le question-réponse, le résumé, la classification de textes avec peu d’exemples (few-shot), et bien plus.\n",
    "\n",
    "Pour installer Sentence Transformers, voici la commande officielle :\n",
    "\n",
    "```bash\n",
    "pip install sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd62fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version :  5.1.2\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "\n",
    "print(\"Version : \", sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfe346",
   "metadata": {},
   "source": [
    "##### **2.2. Charger le Modèle `paraphrase-multilingual-MiniLM-L12-v2` :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c925893",
   "metadata": {},
   "source": [
    "Le `paraphrase-multilingual-MiniLM-L12-v2` est un modèle de la famille **Sentence Transformers**, entraîné pour générer des embeddings de phrases capables de mesurer la similarité sémantique entre textes. \n",
    "\n",
    "Ce modèle est multilingue, couvrant plus de 50 langues, ce qui lui permet de comprendre et comparer des phrases écrites dans différentes langues tout en gardant un espace vectoriel commun. \n",
    "\n",
    "Il est basé sur **MiniLM**, une architecture Transformer légère et rapide, composée ici de 12 couches, offrant un excellent compromis entre performance, vitesse et taille du modèle. \n",
    "\n",
    "En pratique, il est utilisé pour des tâches comme la détection de paraphrases, la recherche sémantique, le clustering de textes ou la classification, surtout lorsque l’on travaille sur des données multilingues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16425007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09deec",
   "metadata": {},
   "source": [
    "##### **2.3. Encoder les Textes :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbfe94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = df_train[\"text\"].tolist()\n",
    "texts_test = df_test[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a512c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3750/3750 [43:00<00:00,  1.45it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.08452066, -0.01008103,  0.06637681, ..., -0.06347683,\n",
       "         0.06138301,  0.06853291],\n",
       "       [ 0.05757697, -0.04762953, -0.05892563, ..., -0.05354639,\n",
       "         0.10166489,  0.07635632],\n",
       "       [ 0.00769315, -0.05420009,  0.0099926 , ..., -0.07634497,\n",
       "        -0.02036024,  0.05035335],\n",
       "       ...,\n",
       "       [-0.00733379,  0.01531467, -0.03676148, ...,  0.0200584 ,\n",
       "         0.02946613,  0.04843622],\n",
       "       [-0.04644714, -0.00755117, -0.00477977, ..., -0.02791102,\n",
       "        -0.03229308,  0.02573509],\n",
       "       [ 0.00502691, -0.02269462,  0.00718506, ...,  0.00981893,\n",
       "        -0.01004013, -0.04893992]], shape=(120000, 384), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = model.encode(texts_train, normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "embeddings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d53195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 238/238 [02:40<00:00,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01411231,  0.15086146, -0.02255305, ..., -0.01153259,\n",
       "         0.02307641,  0.03963377],\n",
       "       [-0.01088149,  0.06553683, -0.02277297, ..., -0.03347767,\n",
       "        -0.13197821,  0.0141266 ],\n",
       "       [-0.07935794, -0.00152846, -0.05285733, ...,  0.0270975 ,\n",
       "         0.06568895,  0.05936584],\n",
       "       ...,\n",
       "       [ 0.02158561, -0.00492702,  0.05524898, ..., -0.00168797,\n",
       "         0.05362756, -0.03379632],\n",
       "       [-0.02377791,  0.00538047,  0.03565134, ..., -0.09892855,\n",
       "         0.03224505,  0.05978754],\n",
       "       [ 0.03612331, -0.03080175,  0.03020013, ..., -0.10219812,\n",
       "         0.00145259, -0.05525691]], shape=(7600, 384), dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test = model.encode(texts_test, normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "embeddings_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0336733",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">**3. Sauvegarder les Datasets après Embedding :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Sauvegardé avec Succès !\n"
     ]
    }
   ],
   "source": [
    "df_train[\"text_embedding\"] = embeddings_train.tolist()\n",
    "\n",
    "df_train[\"id\"] = \"train_art_\" + df_train.index.astype(str)\n",
    "\n",
    "df_train.to_pickle(\"../metadatas/train.pkl\")\n",
    "\n",
    "print(\"Train Dataset Sauvegardé avec Succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ad81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Sauvegardé avec Succès !\n"
     ]
    }
   ],
   "source": [
    "df_test[\"text_embedding\"] = embeddings_test.tolist()\n",
    "\n",
    "df_test[\"id\"] = \"test_art_\" + df_test.index.astype(str)\n",
    "\n",
    "df_test.to_pickle(\"../metadatas/test.pkl\")\n",
    "\n",
    "print(\"Test Dataset Sauvegardé avec Succès !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
